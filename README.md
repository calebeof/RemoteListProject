# Remote List Project
This project aims to develop a Distributed System that consists of a component called RemoteList, which manages a set of lists of integer values, and a set of clients that use the service offered by RemoteList (i.e., insertion, querying, and removal of elements in lists). In this way, RemoteList acts as a server and stores data submitted by clients in lists (more than one list can exist, and each list must have a unique identifier). It also allows remote clients to query data from the list from any position, as well as remove data from the list, but only the value at the end of the list. Multiple clients can use the services offered by RemoteList simultaneously and use common lists.

A synchronous (the client receives confirmation of the operation performed) and persistent (data remains stored even if clients or the server stop executing) communication scheme was implemented using Remote Procedure Call (RPC). In this way, the following operations are available to clients via RPC:

* Append(list_id, v) -> adds the value v at the end of the list with the identifier list_id.
* Get(list_id, i) -> returns the value at position i in the list with the identifier list_id.
* Remove(list_id) -> removes and returns the last element of the list with the identifier list_id.
* Size(list_id) -> obtains the number of elements stored in the list with the identifier list_id.

The system also allows concurrent access to the lists, and ensure data consistency and reliability in the face of failures.

This project is a fork of https://github.com/ruandg/SD_PPGTI and is part of a requirement for the PPGTI Distributed Systems classes.
## Implementation

To run this system, you can just go to the *remotelist* directory and execute in separate terminals the following commands:

```
go run remote_rpc_client.go
```
```
go run remote_rpc_server.go
```

The server will listen on localhost:5000. You can instantiate lots of clients (in different terminals) as you want (or your machine can). On the client-side, just follow the instructions that the system requires.

Lists will be saved on ```.txt``` files inside the ```remotelist/RemoteLists``` directory, and just one number per line is going to be registered.

Unit tests and the proper functions for the remote list are implemented on ```remotelist/pkg``` directory.

This system was implemented using Go 1.20.3.

## Discussions and limitations

The proposed distributed system has some interesting features in terms of scalability, availability, and consistency, but also has some limitations and points of failure that are needed to be considered.

The system supports multiple clients and only one server for the moment. This implies that the server is a single point of failure: if it's down, the system can't actually respond as intended.

Regarding scalability, the proposed solution allows multiple clients to use the services offered by RemoteList simultaneously and use shared lists. This is possible due to the use of RPC and the mutual exclusion mechanism between threads that serve different clients simultaneously on the server side. However, scalability may be limited by the server's capacity to manage and store multiple lists and the network traffic generated by the use of RPC. One possible solution to improve scalability would be to use a distributed caching system, such as Memcached or Redis, to store lists in memory and reduce the need for access to persistence files.

Regarding availability, the proposed solution allows list data to be stored in files and loaded into main memory during service execution, ensuring that data remains stored even if clients or the server stop executing. In addition, the system handles failures by recovering the last saved state of the list in the files when restarted. However, the system may be affected by hardware or network failures, which may prevent access to persistence files or cause data loss. In this case, it would be important to use data replication techniques and hardware redundancy to ensure system availability.

Regarding consistency, the proposed solution has some limitations. The mutual exclusion mechanism used to ensure data consistency may cause delays in processing requests, especially in scenarios with many simultaneous clients. In addition, removing elements from the list is limited to the last element, which may cause concurrency issues in scenarios where multiple clients attempt to remove elements at the same time. To improve consistency, it would be possible to use more advanced locking techniques, such as optimistic locking or pessimistic locking, to allow concurrent access to data with consistency guarantees.

In summary, the proposed solution has some limitations in terms of scalability, availability, and consistency, but also has some interesting features to address these problems. To improve scalability, it would be necessary to use distributed caching techniques or data partitioning. To improve availability, it would be necessary to use data replication techniques and hardware redundancy. To improve consistency, it would be necessary to use more advanced locking techniques. It's important to carefully evaluate the system's needs and choose the most appropriate techniques for each scenario.